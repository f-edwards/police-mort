{
    "collab_server" : "",
    "contents" : "#########################\n# Fatal Encounters Data\n# Main file, .R\n#########################\n\n## Set-up\n# 1: load packages; setwd etc. \nrm(list=ls())\nset.seed(1)\n\nlibrary(ggplot2)\nlibrary(readr)\nlibrary(date)\nlibrary(lme4)\nlibrary(MASS)\nlibrary(rstanarm)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(xtable)\noptions(mc.cores = parallel::detectCores())\n\nfdat<-read.csv(\"fe-clean.csv\", stringsAsFactors = FALSE)\n# 2: configure data ...\n# ... attach fatal encounters data\n#fdat = read.csv('fdat.csv',\n#\t\t\t\t stringsAsFactors = FALSE) %>%\n#\t   filter(year >= 2013) %>%\n#\t   mutate(county = paste(county, 'county', sep = ' '))\n\nfdat = fdat %>%\n\t   mutate(county = paste(county, 'county', sep = ' '),\n\t   \t      year.death = year) %>%\n\t   dplyr::select(-year) %>%\n\t   mutate(race = ifelse(race == 'African-American/black', \n\t  \t\t\t\t\t\t\t    'African-American/Black', race))\n\n# ... attach CDC urban-rual scheme\ncdc = read_fwf(file = 'NCHSURCodes2013.txt', \n\t\t\t   fwf_positions(c(1, 3, 7, 10, 47, 98, 107, 116, 118, 120), \n\t\t\t\t\t  \t\t c(2, 5, 8, 45, 96, 105, 114, 116, 118, 120))\n\t\t) %>%\n\t  dplyr::select(X1, X2, X3, X4, X8) %>%\n\t  rename(s.fips = X1, c.fips = X2, state = X3, county = X4, ur.code = X8) %>%\n\t  mutate(county = tolower(county),\n\t  \t     ur.code = ifelse(ur.code == 1, '1: large central metro',\n\t  \t     \t\t   ifelse(ur.code == 2, '2: large fringe metro',\n\t  \t     \t\t   ifelse(ur.code == 3, '3: medium metro',\n\t  \t     \t\t   ifelse(ur.code == 4, '4: small metro', \n\t  \t     \t\t   ifelse(ur.code == 5, '5: micropolitan', \n\t  \t     \t\t   ifelse(ur.code == 6, '6: noncore', NA))))))) %>%\n\t  mutate(fips = as.numeric(paste0(s.fips, c.fips))) %>%\n\t  dplyr::select(fips, ur.code)\n\n# ... attach census division codes\nregions = read.csv('regions.csv', \n\t\t\t\t\tstringsAsFactors = FALSE) %>%\n\t\t  mutate(state = State.Code) %>%\n\t\t  dplyr::select(state, Division)\n\n# ... demographics\npop<-read.csv(\"nhgis0022_ds215_20155_2015_county.csv\", colClasses = \"character\")\n\npop$fips<-paste(pop$STATEA, pop$COUNTYA, sep=\"\")\n\npop$latino<-as.numeric(pop$ADK5E012)\npop$white<-as.numeric(pop$ADK5E003)\npop$black<-as.numeric(pop$ADK5E004) + as.numeric(pop$ADK5E014)\npop$amind<-as.numeric(pop$ADK5E005) + as.numeric(pop$ADK5E015)\npop$api<-as.numeric(pop$ADK5E006)+\n  as.numeric(pop$ADK5E007)+\n  as.numeric(pop$ADK5E016)+as.numeric(pop$ADK5E017)\npop$tot.pop<-as.numeric(pop$ADK5E001)\npop<-pop%>%\n  rename(fips.st=STATEA)%>%\n  dplyr::select(fips, tot.pop, latino, white, black, amind, api, fips.st) %>%\n\t\t\t\t   mutate(fips = as.numeric(fips), fips.st=as.numeric(fips.st))%>%\n  filter(fips.st!=72)\n\ncw<-read.csv(\"fips-st-crosswalk.csv\", stringsAsFactors = FALSE)%>%\n  dplyr::select(state, fips)%>%rename(fips.st=fips)\n\npop<-left_join(pop, cw)%>%\n  dplyr::select(-fips.st)\n\nfdat$fips<-ifelse((fdat$county==\"shannon county\")&(fdat$state==\"SD\"), 46102, fdat$fips)\nfdat$fips<-ifelse((fdat$city==\"Chevak\")&(fdat$state==\"AK\"), 2158, fdat$fips)\n\n### got all of them matched\n#z<-which(!(fdat$fips%in%pop$fips))\n\n### rewrite for inclusion of all US counties - current setup miscalculates low pop based on zeroes in the data\ntmp1 = left_join(pop, cdc, c('fips')) %>%\n\t   full_join(fdat, c('fips', 'state')) %>%\n\t   left_join(regions, 'state') %>% \n\t   filter(!is.na(ur.code)) %>%\n\t   rename(division = Division) %>%\n\t   group_by(fips, race) %>%\n\t   mutate(d.count = n()) %>%\n\t   dplyr::select(fips, ur.code, division, race, d.count, tot.pop, latino, white, black, amind, api) %>%\n\t   arrange(fips, race) %>%\n\t   ungroup() %>%\n\t   distinct() %>%\n\t   group_by(fips) %>%\n\t   spread(race, d.count, fill = 0) %>% \n\t   rename(d.black  = `African-American/Black`,\n\t  \t\t  d.white  = `European-American/White`,\n\t  \t\t  d.latino = `Hispanic/Latino`,\n\t  \t\t  d.amind  = `Native American/Alaskan`,\n\t  \t\t  d.api    = `Asian/Pacific Islander`,\n\t  \t\t  d.mid    = `Middle Eastern`,\n\t  \t\t  d.na     = `Race unspecified`) %>%\n     mutate(d.total=d.black+d.api+d.white+d.latino+d.mid+d.amind+d.na)%>%\n  dplyr::select(-`<NA>`)\n\n\n#######################################\n### models\n#######################################\n### drop na, only two cases\n### setting intercept priors from http://harvardpublichealthreview.org/190/\n### mort for black=0.94, white =0.37 from 2005\n### B_0 +... =log(mort)-log(offset)\n### high variance for weak information\n### for offset=100000, p(B_0)~N(log(mort)-log(offset), 10)\n### so for blk, p(B_0)~N(log(0.94)-log(100000), 10)\n### for white, p(B_0)~N(log(0.37)-log(100000), 10)\n### use white for all, use white for latino\n\n\ntmp2<-tmp1\n\n# all= glmer.nb(d.total ~  ur.code + (1|division),\n#            data = tmp1, offset=log(tot.pop), verbose=TRUE, control=glmerControl(optimizer=\"bobyqa\",\n#                                                                                 optCtrl=list(maxfun=2e5)))\n\n# all.stan = stan_glmer(d.black ~ ur.code + (1|division),\n#                       prior_intercept=normal((log(0.37)-log(100000)), 10), #for prior intercept, based on krieger estimates\n#                       prior = normal(0, 2.5), #weakly informative, no difference from big urban\n#                       prior_covariance = decov(1, 1, 1, 1), #default\n#                       data = tmp2, offset=log(tot.pop), family=\"neg_binomial_2\", iter=2000, chains=4)\n\n\n# blk = glmer.nb(d.black ~  ur.code + (1|division) + (1|fips),\n#            data = tmp1, offset=I(log(black+1)), verbose=TRUE, control=glmerControl(optimizer=\"bobyqa\",\n#                                                                                    optCtrl=list(maxfun=2e5)))\n\ntot.stan = stan_glmer(d.total ~ ur.code + (1|division),\n                      prior_intercept=normal((log(0.37)-log(100000)), 10), #for prior intercept, based on krieger estimates\n                      prior = normal(0, 2.5), #weakly informative, no difference from big urban\n                      prior_covariance = decov(1, 1, 1, 1), #default\n                      data = tmp2, offset=I(log(tot.pop+1)), family=\"neg_binomial_2\", iter=2000, chains=4)\n\n\n\nblk.stan = stan_glmer(d.black ~ ur.code + (1|division),\n                      prior_intercept=normal((log(0.94)-log(100000)), 10), #for prior intercept, based on krieger estimates\n                      prior = normal(0, 2.5), #weakly informative, no difference from big urban\n                      prior_covariance = decov(1, 1, 1, 1), #default\n                     data = tmp2, offset=I(log(black+1)), family=\"neg_binomial_2\", iter=2000, chains=4)\n\n# wht = glmer.nb(d.white ~  ur.code + (1|division) + (1|fips),\n#                data = tmp1, offset=log(white), verbose=TRUE, control=glmerControl(optimizer=\"bobyqa\",\n#                                                                                   optCtrl=list(maxfun=2e5)))\n\nwht.stan = stan_glmer(d.white ~ ur.code + (1|division),\n                      prior_intercept=normal((log(0.37)-log(100000)), 10), #for prior intercept, based on krieger estimates\n                      prior = normal(0, 2.5), #weakly informative, no difference from big urban\n                      prior_covariance = decov(1, 1, 1, 1), #default\n                      data = tmp2, offset=log(white), family=\"neg_binomial_2\", iter=2000, chains=4)\n\n# lat = glmer.nb(d.latino ~  ur.code + (1|division) + (1|fips),\n#                data = tmp1, offset=I(log(latino+1)), verbose=TRUE, control=glmerControl(optimizer=\"bobyqa\",\n#                                                                                    optCtrl=list(maxfun=2e5)))\n\nlat.stan = stan_glmer(d.latino ~ ur.code + (1|division),\n                      prior_intercept=normal((log(0.37)-log(100000)), 10), #for prior intercept, based on krieger estimates\n                      prior = normal(0, 2.5), #weakly informative, no difference from big urban\n                      prior_covariance = decov(1, 1, 1, 1), #default\n                      data = tmp2, offset=I(log(latino+1)), family=\"neg_binomial_2\", iter=2000, chains=4)\n\nsave.image(\"models.RData\")\n\n\n\n### for natl descriptives\n###Population estimates, July 1, 2015, (V2015)321,418,820\n\n\n## ... populatuion counts \n#tmp2 = left_join(fdat, cdc, 'fips') %>%\n#\t   inner_join(regions, 'state') %>%\n#\t   left_join(pop, 'fips') %>% \n#\t   rename(division = Division) %>%\n#\t   select(fips, ur.code, division, white, black, amind, api, latino) %>%\n#\t   distinct(.keep_all = TRUE) %>%\n#\t   group_by(ur.code, division) %>%\n#\t   mutate(cd_pop.black  = sum(black),\n#\t   \t\t  cd_pop.white  = sum(white),\n#\t   \t\t  cd_pop.latino = sum(latino),\n#\t   \t\t  cd_pop.api    = sum(api), \n#\t   \t\t  cd_pop.amind  = sum(amind)) %>%\n#\t   distinct(.keep_all = TRUE) %>%\n#\t   select(ur.code, division, 9:13) %>%\n#\t   arrange(ur.code, division) #\n\n## ... merge \n#tmp = inner_join(tmp1, tmp2, c('ur.code', 'division')) %>%\n#\t  spread(race, n) %>%\n#\t  arrange(ur.code, division) %>%\n#\t  rename(count.black  = `African-American/Black`,\n#\t  \t\t count.white  = `European-American/White`,\n#\t  \t\t count.latino = `Hispanic/Latino`,\n#\t  \t\t count.amind  = `Native American/Alaskan`,\n#\t  \t\t count.api    = `Asian/Pacific Islander`,\n#\t  \t\t count.mid    = `Middle Eastern`,\n#\t  \t\t count.na     = `Race unspecified`) %>%\n#\t  mutate(y.black  = (count.black/cd_pop.black)*100000,\n#\t  \t\t y.white  = (count.white/cd_pop.white)*100000,\n#\t  \t\t y.latino = (count.latino/cd_pop.latino)*100000,\n#\t  \t\t y.api    = (count.api/cd_pop.api)*100000,\n#\t  \t\t y.amind  = (count.amind/cd_pop.amind)*100000) %>%\n#\t  mutate(b.w = y.black/y.white) #\n\n#dat = tmp %>%\n#\t  select(ur.code, division, count.black, count.white, y.black, y.white, )#\n\n### Analysis\n## 1: plot rates \n#plotDat = tmp %>%\n#\t\t  gather(race, rate, y.black:y.amind) %>%\n#\t\t  mutate(rate = ifelse(is.na(rate), 0, rate))#\n\n#ggplot(plotDat, aes(y = rate, x = ur.code, group = race, \n#\t\t\t\t\tcolor = race)) +\n#\tgeom_point(alpha = .6, size = 4) +\n#\tfacet_wrap(~division) + \n#\ttheme_bw() + \n#\tcoord_flip() +\n#\tylab('Rate, per 100,000') +\n#\txlab('CDC Type') +\n#\tscale_color_brewer(palette = 'Set2')#\n\n## 2: plot black rate/white rate\n#ggplot(tmp, aes(y = b.w, x = ur.code, group = division, color = division, \n#\t\t\t\tsize = log(cd_pop.black))) +\n#\tgeom_point(alpha = .6, size = 4) + \n#\ttheme_bw() + \n#\t#coord_flip() +\n#\t#geom_smooth(se = FALSE) +\n#\tylab('B/W Rate') +\n#\txlab('CDC Type') #\n\n# 2: model\n\n\n#a = tmp1 %>%\n#\tselect(ur.code, race, count) %>% \n#\tdistinct(.keep_all = TRUE)#\n#\n#\n\n## need the population of each ur.type#\n\n#a = tmp1 %>%\n#\tungroup() %>%\n#\tgroup_by(ur.code) %>%\n#\tmutate(ur.black = sum(black))#\n\n## ... gather county population numbers\n#tmp2 = tmp1 %>%\n#\t   gather(c.race, c.pop, c(white, black, latino, amind, api)) %>%\n#\t   gather(c.pop, value, c.pop) %>%\n#\t   mutate(i.race = ifelse(race == 'African-American/Black',  'black',\n#\t   \t\t\t\t   ifelse(race == 'Asian/Pacific Islander',  'api',\n#\t   \t\t\t\t   ifelse(race == 'European-American/White', 'white',\n#\t   \t\t\t\t   ifelse(race == 'Native American/Alaskan', 'amind',\n#\t   \t\t\t\t   ifelse(race == 'Hispanic/Latino',         'latino', 'other')))))) %>%\n#\t   ungroup() %>%\n#\t   select(ur.code, i.race, count, c.race, c.pop, value, division)#\n#\n#\n\n##checks\n#filter(tmp1, fips == 1003)#\n\n#able(filter(fdat, fips == 1073)$race) #\n#\n\n#tmp2 = tmp1 %>% \n#\t   group_by(Division) %>%\n#\t   summarise(black.d_pop  = sum(black,  na.rm = TRUE),\n#\t   \t\t\t white.d_pop  = sum(white,  na.rm = TRUE),\n#\t   \t\t\t latino.d_pop = sum(latino, na.rm = TRUE),\n#\t   \t\t\t amind.d_pop  = sum(amind,  na.rm = TRUE), \n#\t   \t\t\t api.d_pop    = sum(api,    na.rm = TRUE))#\n\n#tmp = left_join(tmp1, tmp2, 'Division') #\n#\n#\n\n## ... get counts by county\n#hold = tmp %>% \n#\t   group_by(ur.code, race) %>%\n#\t   select(ur.code, race) %>%\n#\t   mutate(n = n())#\n\n#tmp.black = tmp %>%\n#\t\t\tfilter(race == 'African-American/Black') %>%\n#\t\t\tselect(race, county, ur.code, Division, black, black.d_pop) %>%\n#\t\t\tmutate(n = n(),\n#\t\t\t\t   countcount.off  = n/black,\n#\t\t\t\t   divison.off = n/black.d_pop) %>%\n#\t\t\trename(pop = black,\n#\t\t\t\t   black.d_pop = black_pop_division)#\n#\n\n#tmp.white = tmp %>%\n#\t\t\tfilter(race == 'European-American/White') %>%\n#\t\t\tselect(race, county, ur.code, Division, white, white.d_pop) %>%\n#\t\t\tmutate(n = n(),\n#\t\t\t\t   countcount.off  = n/white,\n#\t\t\t\t   divison.off = n/white.d_pop) #\n\n#tmp.all = #\n#\n\n###########################\n###########################\n######### Analysis ########\n###########################\n############################\n\n### 1: EDA\n## 1a: cases by urban-rual\n#table(tmp$ur.code) %>% plot()#\n\n## 2a: ... by dividion \n#table(tmp$Division) %>% plot()#\n\n## 3a: cases, by race, by urban-rual code x divison\n#pDat1 = tmp %>%\n#\t\tselect(race, ur.code, Division) %>%\n#\t\tgroup_by(race, ur.code, Division) %>%\n#\t\tsummarise(n = n()) %>%\n#\t\tmutate(ur.div = paste(ur.code, Division, sep = ',')) #\n\n#ggplot(pDat1, aes(x = ur.code, y = n, group = race, color = race)) +\n#\tgeom_jitter(size = 4, width = 0.5, alpha = .8) +\n#\ttheme_bw() +\n#\tscale_color_brewer(palette = 'Set2') +\n#\tfacet_wrap(~ Division) +\n#\tcoord_flip()\n\n\n",
    "created" : 1506439079284.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3267637495",
    "id" : "675F9377",
    "lastKnownWriteTime" : 1506439135,
    "last_content_update" : 1506439135576,
    "path" : "C:/Users/fre9/Box Sync/police-mort/main_code.r",
    "project_path" : "main_code.r",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}