---
title: "Race, place, and deaths involving police"
author: "Frank Edwards, Mike Esposito and Hedy Lee"
date: "May 17, 2017"
output: pdf_document
---
```{r setup, echo=FALSE, asis=TRUE, message=FALSE, warning=FALSE}
library(MASS)

library(ggplot2)
library(readr)
library(date)
library(rstanarm)
library(dplyr)
library(tidyr)
library(xtable)
library(pander)
load("models.RData")

```

# Abstract
*Objective.* To estimate mortality for police-involved deaths by race and geography in the United States.

*Methods.* We estimate mortality rates for deaths involving police by race and by census region using data on all police-involved deaths between 2013 and 2017. We estimate multilevel Bayesian Poisson models that adjust for unobserved geographic characteristics and allow for more predictive precision for rare events, such as law enforcement deaths.

*Results.* Summarize mortality estimates. Summarize fit on observed. Summarize variation across places, races, metros.

*Conclusions.* Abrupt statement

*Policy Implications.* Efforts to address should take race, place seriously. Clear mort risk for PoC, treat as pub health problem


OUTLINE - 

SINGLE FIGURE WITH RAW/SMOOTH

TABLE WITH MODELED ESTIMATES - TABLE WITH RAW ESTIMATES AS APPENDIX

FIGURE

# Introduction

Violent and fatal interactions between law enforcement and people of color are a persistent feature of American social life [@james_warfare_2007; @alang_police_2017]. In response to the shortcomings of federal efforts to systematically document deaths involving police [@krieger_police_2015], newspapers and journalists have undertaken a series of systematic efforts to provide comprehensive data on fatalities resulting from interactions between police and the public [@burghart_fatal_2015]. This analysis utilizes these new data to provide estimates of mortality risk from interactions with police by race and place. 

Race, place, and policing are important social determinants of health [@cooper_editorial_2016; @crosby_assessing_2016; @furtado_research_2016]. Prior research has clearly established that African Americans are at higher risk of death in interactions with law enforcement [@krieger_trends_2015; @wildeman_mortality_2016] and has demonstrated clear links between race, place and health outcomes [@dwyer-lindgren_inequalities_2017]. The legal, cultural, and institutional environments structuring relationships between police and communities of color are tightly coupled with geography. In this paper, we show how geography and race interact to produce variable risks for mortality in encounters with law enforcement for people of color.

# Background

Prior research suggests that MORTALITY = X.

In multivariate analyses, researchers have found structural inequality as potential causes.

Why place should matter - politics/institutions, culture/racism, structural ineq/demog.





BJS estimates 1900 for may31-june 2016 - read those reports in more detail. talk abt cops+media+ME/C data as gold standard


WHY WE HAVE SHITTY DATA. Sources and limitations

We have lacked reliable national official data on deaths resulting from police action, in part because reporting to the federal government is voluntary, and police agencies have strong disincentives to report officer-involved deaths. DICRA makes reporting deaths in custody/arrest condition of DoJ funding (2014). New design, get prelim reports, survey departments after initial list, survey med examiners. 


Concise lit review with no more than 35 references


# Data and Methods

The U.S. Bureau of Justice Statistics (BJS) collects data on officer-involved fatalities through the Arrest-Related Deaths Program, but submissions from law enforcement agencies are voluntary and widely acknowledged to provide extreme undercounts of deaths involving police. *Public health scholars have used ME data, ER data, but limited coverage*. Journalists, activists and researchers have stepped in to fill this information gap by constructing a series of public datasets that count police-involved deaths using a combination of public records and media accounts. In response to the limits of official data, BJS has undertaken a redesign of the Arrest-Related Deaths Program that more closely matches the methodology of these public data collection projects. In a pilot report, BJS researchers identified *Fatal Encounters* as closely matching the 

Data on police-involved deaths come from *Fatal Encounters*, a project that seeks to document all episodes of fatal police-civilian interactions in the United States [@burghart_fatal_2015]. The project relies on contributions of professional and volunteer researchers, compiled from media reports and public records. The universe of cases in *Fatal Encounters* is broader than similar projects, such as *The Washington Post's* compilation of data on police shootings, has a greater temporal coverage than *The Guardian's* dataset on police-involved deaths, and has a greater geographic coverage than CDC MORT SYSTEM. We calculate county-level mortality rates by race and ethnicity for the period between January 1, 2013 and May 8, 2017. We rely on data from the American Community Survey 5-year 2009 - 2014 population estimates for rate denominators of population by race, ethnicity and county [RUGGLES]. For geographic classification, we rely on the U.S. Census Bureau's 2010 state division classification (see Table X), and use the National Center for Health Statistics' 6 category urban-rural county classification scheme for all US counties.

Because deaths in police custody are a relatively rare event ADD TOTAL INCIDENCE RATE HERE, we construct regression models to pool power across data to provide predictions of mortality rates by race, by metropolitan status, and by region. These figures provide more reliable estimates of police mortality rates by adjusting for the rarity of this event in small population places. Race data are not completely reported in *Fatal Encounters*, because they are often excluded from news reports or public records. We use victim names and county of residence to predict victim race [@imai_improving_2016], only assigning race in cases with a 75 percent or higher posterior probability of membership, and leaving those cases with less than a 75 percent posterior probability of membership in any category unidentified (X percent of cases).

We estimate multilevel Poisson regressions of police-involved deaths as a function of the race of the victim, metropolitan status, and region. We then estimate posterior predictive mortality rates for each subset of race by metropolitan status by region. While frequentist inferences may be appropriate for counties with large populations, they greatly distort estimates from places with small populations, where any incident can dramatically effect estimates of per capita rates. Bayesian predictive intervals provide more realistic estimates of population mortality rates, because they average over the instabilities that may occur as a result of idiosyncratic local or annual trends through large numbers of simulations. 

Why Bayes and regression? Tons of zeroes - these aren't actual indicators of zero risk, just zero incidence in the window for which we have data. This approach lets us estimate plausible levels of population risk for those counties that have had exceedingly high rates due to small denominators and for counties with zeroes. Risk is unlikely to be true zero. 

Models:

alpha (intercept prior) calculated from Krieger et al. 2015

$$log(E(y|X)) = \beta_0 + \beta_1x + \gamma + \varepsilon + log(offset)$$
$$\beta_0 \sim Normal(log(\alpha) - log(offset), 10) $$
$$ \beta_1 \sim Normal (0, 2.5) $$
$$ \gamma, \varepsilon \sim MVN(0, \Sigma) $$
$$ \Sigma \sim decov(1, 1, 1, 1) $$

# Findings

Table on cause of death by region

TABLE1 - COUNTS OF EVENTS BY UR, BY REGION
FIG1 - RAW/SMOOTHED Pacific / East North Central
FIG2 - HEATMAP
FIG3 - DISPARITIES

APPX1 - MODELED / RAW RATE ESTIMATES


East North Central: WI, MI, IL, IN, OH

East South Central: KY, TN, AL, MS

Middle Atlantic: NY, PA, NJ

Mountain: MT, ID, WY, NV, UT, CO, AZ, NM

New England: ME, VT, NH, MA, CT, RI

Pacific: AK, HI, WA, OR, CA

South Atlantic: DE, MD, WV, VA, NC, SC, GA, FL

West North Central: ND, SD, NE, KS, MN, IA, MO

West South Central: OK, TX, AR, LA

Big takeaway: the posterior predictive estimates smooth out the extremes in estimates from small population counties. They also provide more reasonably estimates for the counties with zero observed estimates. For reasonable estimates of population risk, these posterior estimates are superior to the frequentist alternative. 

African Americans at much higher risk of mortality than are whites, risk is generally highest in medium metros, Pacific states. Latino risk also generally higher than white risk, sensitive to division, highest in non-large metro counties, highest in non-core. 

Place matters. Clear regional and metro differences. Pacific states have exceptionally high inequalities. Suggests that local culture, institutions, politics, and systems of structural inequality shape risk.  

```{r, echo=FALSE, message=FALSE}

################################
########## Analysis ############
################################

# 1: EDA
# just pulling fips's over 1000 of each
# tmp = tmp1 %>%
# 	  filter(black >= 1000, white >= 1000)
# 
# # keep most observations, but still
# sum(tmp$d.black)
# sum(tmp$d.white)
# 
# # ... distrbution of rates 
# summary(tmp$y.black)
# summary(tmp$y.white)
# 
# # ... distrbution of counts
# # overwhelmingly 1-2 per county
# summary(tmp$d.black)
# summary(tmp$d.white)
# 
# plot(table(tmp$d.black))
# plot(table(tmp$d.white))
# 
# # ... rate var by county
# dat1 = tmp %>%
# 	   gather(y.race, y.rate, y.black: y.amind) %>%
# 	   select(fips, y.race, y.rate, ur.code, division) %>%
# 	   filter(y.race %in% c('y.black', 'y.white'))
# 
# ggplot(dat1, aes(x = fips, y = log(y.rate), color = y.race)) +
# 	geom_jitter(alpha = .35)  +
# 	theme_bw() +
# 	scale_color_brewer(palette = 'Set2') +
# 	coord_flip() +
# 	ylab('(log) Rate Killed')

# ... average rate by urban/rural type
dat2 = tmp1 %>%
	   group_by(ur.code) %>% 
	   summarise(y.black.mean  = sum(d.black)/sum(black)*100000,
	             y.latino.mean = sum(d.latino)/sum(latino)*100000,
	  			     y.white.mean  = sum(d.white)/sum(white)*100000) %>%
	   gather(rate, value, y.black.mean:y.white.mean )

ggplot(dat2, aes(x = ur.code, y = value, color = rate, group = rate)) +
	geom_point() +
	geom_line() +
	theme_bw() +
	scale_color_brewer(palette = 'Set2') +
	xlab('CDC Code') +
	ylab('Average Rate Killed, per 100,000')+
  theme(axis.text.x = element_text(angle = 75, hjust = 1))+
  ggtitle("Observed mean mortality from interactions with law\nenforcement by race/ethnicity, and metro type")


# ... average rate by division 
dat3 = tmp1 %>%
	   group_by(division) %>% 
	   summarise(y.black.mean  = sum(d.black)/sum(black)*100000,
	             y.latino.mean = sum(d.latino)/sum(latino)*100000,
	  			     y.white.mean  = sum(d.white)/sum(white)*100000) %>%
	   gather(rate, value, y.black.mean:y.white.mean)

ggplot(filter(dat3),
	aes(x = division, y = value, color = rate, group = rate)) +
	geom_point() +
	theme_bw() +
	scale_color_brewer(palette = 'Set2') +
  geom_line()+
	xlab('CDC Code') +
	ylab('Average Rate Killed, per 100,000') +
  theme(axis.text.x = element_text(angle = 75, hjust = 1))+
  ggtitle("Observed mean mortality from interactions with law\nenforcement by race/ethnicity and region")
```

```{r, r, echo=FALSE, fig.height=9, fig.width=7}
# ... average rate by interaction 
dat4 = tmp1 %>%
	   group_by(ur.code, division) %>%
	   summarise(y.black.mean  = sum(d.black)/sum(black)*100000,
	             y.latino.mean = sum(d.latino)/sum(latino)*100000,
	  			     y.white.mean  = sum(d.white)/sum(white)*100000) %>%
	   gather(rate, value, y.black.mean:y.white.mean)

ggplot(filter(dat4),
	   aes(x = ur.code, y = value, group = rate, color = rate)) +
	facet_wrap(~division) + 
	geom_point(size = 2) +
	geom_line() +
	#coord_flip() +
	theme_bw() +
	scale_color_brewer(palette = 'Set2') +
  coord_cartesian(ylim=c(0, 20))+
	xlab('CDC Code') +
	ylab('Rate Killed, per 100,000') +
	theme(axis.text.x = element_text(angle = 75, hjust = 1, size = 9))+
  ggtitle("Observed mean mortality from interactions with law\nenforcement by race/ethnicity, and metro type")



```

Bayesian estimates

```{r, echo=FALSE, message=FALSE, fig.height=9, fig.width=7}
# z<-posterior_predict(blk.stan, newdata=tmp1)
# 
# ### plot mean ppd vs observed, looks alright
# plot(tmp1$d.black, apply(z, 2, mean))
# abline(0, 1)
# 
# prop_zero <- function(y) mean(y == 0)
# prop_zero_test <- pp_check(blk.stan, plotfun = "stat", stat = "prop_zero")

#### do ppd checks for each race/region/ur combo with 100k pop
#### obtain pp intervals for each combo
#### obtain diff/ratio of intervals for each combo
ur.code<-unique(tmp2$ur.code)
division<-unique(tmp2$division)
ur.division<-expand.grid(division, ur.code); names(ur.division)<-c("division", "ur.code")
n<-length(division)*length(ur.code)
### set up newdata for ppd - use 100,000,000 for offset to get enough trials, then rescale to rate per 100,000
newdata<-tmp2[1:n,]
newdata$fips<-0; newdata$tot.pop<-newdata$black<-newdata$white<-newdata$latino<-100000000; 
newdata$ur.code<-ur.division$ur.code; newdata$division<-ur.division$division

# post.all<-posterior_predict(all.stan, newdata=newdata)/1000
# post.all.int<-bind_cols(ur.division, 
#                         as.data.frame(t(apply(post.all, 2, function(x)quantile(x, probs=c(0.025, 0.5, 0.975))))))

post.blk<-posterior_predict(blk.stan, newdata=newdata)/1000
post.blk.int<-bind_cols(ur.division, 
                        as.data.frame(t(apply(post.blk, 2, function(x)quantile(x, probs=c(0.025, 0.5, 0.975))))))

post.wht<-posterior_predict(wht.stan, newdata=newdata)/1000
post.wht.int<-bind_cols(ur.division, 
                        as.data.frame(t(apply(post.wht, 2, function(x)quantile(x, probs=c(0.025, 0.5, 0.975))))))

post.lat<-posterior_predict(lat.stan, newdata=newdata)/1000
post.lat.int<-bind_cols(ur.division,
                        as.data.frame(t(apply(post.lat, 2, function(x)quantile(x, probs=c(0.025, 0.5, 0.975))))))

# plot.dat<-bind_cols(ur.division, data.frame(value=apply(post.all, 2, median)))
# plot.dat$rate<-"All"

plot.dat<-bind_cols(ur.division, data.frame(value=apply(post.blk, 2, median)))
plot.dat$rate<-"Black"

plot.tmp<-bind_cols(ur.division, data.frame(value=apply(post.wht, 2, median)))
plot.tmp$rate<-"White"

plot.dat<-bind_rows(plot.dat, plot.tmp)

plot.tmp<-bind_cols(ur.division, data.frame(value=apply(post.lat, 2, median)))
plot.tmp$rate<-"Latino"

plot.dat<-bind_rows(plot.dat, plot.tmp)

plot.dat$ur.code<-factor(plot.dat$ur.code, levels=sort(as.character(unique(plot.dat$ur.code))))
plot.dat$division<-factor(plot.dat$division, levels=sort(as.character(unique(plot.dat$division))))

plot.dat<-plot.dat[order(plot.dat$division, plot.dat$ur.code), ]

ggplot(plot.dat,
       aes(x = ur.code, y = value, group = rate, color = rate)) +
  facet_wrap(~division) + 
  geom_point(size = 2) +
  geom_line() +
  #coord_flip() +
  theme_bw() +
  scale_color_brewer(palette = 'Set2') +
  xlab('CDC Code') +
  ylab('Rate Killed, per 100,000') + 
  ylim(0, 15)+
  theme(axis.text.x = element_text(angle = 75, hjust = 1, size = 10))+
  ggtitle("Posterior mean mortality from interactions with law\nenforcement by race/ethnicity, and metro type")

########### get posterior rate ratios
bw.post<-bind_cols(ur.division, 
                   as.data.frame(t(apply(post.blk - post.wht, 2, function(x)quantile(x, probs=c(0.05, 0.5, 0.95))))))
bw.post$rate<-"Black - White"
lw.post<-bind_cols(ur.division, 
                   as.data.frame(t(apply(post.lat - post.wht, 2, function(x)quantile(x, probs=c(0.05, 0.5, 0.95))))))
lw.post$rate<-"Latino - White"

plot.dat<-bind_rows(bw.post, lw.post)

plot.dat$ur.code<-factor(plot.dat$ur.code, levels=sort(as.character(unique(plot.dat$ur.code))))
plot.dat$division<-factor(plot.dat$division, levels=sort(as.character(unique(plot.dat$division))))

plot.dat<-plot.dat[order(plot.dat$ur.code, plot.dat$division), ]
names(plot.dat)[3:5]<-c("Lower", "Median", "Upper")

ggplot(plot.dat,
  aes(x = ur.code, y = Median, group = rate, color = rate)) +
  facet_wrap(~division) + 
  geom_point(size = 2) +
  geom_line() +
  #geom_errorbar(aes(ymin = Lower, ymax= Upper)) +
  theme_bw() +
  scale_color_brewer(palette = 'Set2') +
  xlab('County Type') +
  ylab('Rate difference') + 
  geom_hline(yintercept=0, lty=2)+
  #coord_cartesian(ylim=c(0, 30))+
  theme(axis.text.x = element_text(angle = 75, hjust = 1, size = 10))+
  ggtitle("Posterior difference in mean mortality from interactions with law\nenforcement by race/ethnicity, and metro type")

######################
### Tables
########################

maketable<-function(x, label){
  simpleCap <- function(x) {
    s <- strsplit(x, " ")[[1]]
    paste(toupper(substring(s, 1,1)), substring(s, 2),
          sep="", collapse=" ")
  }
  tab<-x
  names(tab)[3:5]<-c("Lower", "Median", "Upper")
  tab$ur.code<-as.character(tab$ur.code); tab$division<-as.character(tab$division)
  tab<-tab[order(tab$division, tab$ur.code), ]
  tab$ur.code<-substr(tab$ur.code, 4, nchar(tab$ur.code))
  for(i in 1:nrow(tab)){
    tab$ur.code[i]<-simpleCap(tab$ur.code[i])
    tab$ur.code[i]<-paste(" -", tab$ur.code[i])
  }
  tab[, 3:5]<-round(tab[, 3:5], 2)
  tab<-tab%>%mutate(value=paste(Median, " (", Lower, ", ", Upper, ")", sep=""))%>%
    select(-Median, -Lower, -Upper)
  div<-unique(tab$division)
  for(i in 1:length(div)){
    index<-min(which(tab$division==div[i]))
    if(index==1){
      tab<-rbind(c(NA, div[i], NA), tab[index:nrow(tab),])
      }
    if(index!=1){
      tab<-rbind(tab[1:(index-1),], c(NA, div[i], NA), tab[index:nrow(tab),])
      }
  }
  tab<-tab%>%select(-division)
  names(tab)<-c("County Type", label)
  return(tab)
}


tab.out<-cbind(maketable(post.blk.int, "Rate-Black"),
               maketable(post.lat.int, "Rate-Latino")[,2],
               maketable(post.wht.int, "Rate-White")[,2])
names(tab.out)<-c("County Name", "Black", "Latino", "White")
```

Here is a ridiculous table with posterior estimates of mortality by race, region and metro type.

```{r, results="asis", message=FALSE, echo=FALSE}

print(xtable(tab.out,
             caption="Posterior police related mortality estimates by race/ethnicity, census region, and metro type, 95 percent credible intervals"),
      include.rownames=FALSE,
      size="\\fontsize{9pt}{10pt}\\selectfont",
      caption.placement="top",
      comment=FALSE
      )

```


```{r Table 1, results="asis"}
tabUR<-tmp2%>%group_by(ur.code, division)%>%
  summarise(total=sum(d.total))%>%
  spread(ur.code, total)

tabUR$Total<-apply(tabUR[, 2:ncol(tabUR)], 1, sum)
tabUR<-rbind(tabUR, c("Total", apply(tabUR[, 2:ncol(tabUR)], 2, sum)))

names(tabUR)<-c("Division", "Large Central Metro", "Large Fringe Metro",
                "Medium Metro", "Small Metro", "Micropolitan", "Noncore", "Total")

tab.out<-xtable(tabUR, caption = "Police related fatalities in the U.S. by metro type and Census divsiion, 1/1/2013 - 5/8/2017")
print(tab.out, type="html")


#### also make an appx table for 


```
